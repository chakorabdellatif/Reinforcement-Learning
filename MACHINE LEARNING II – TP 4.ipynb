{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2262c4b8-d231-404d-a1a0-da9c8516c9f3",
   "metadata": {},
   "source": [
    "# Exercice 1 : Initialisation de l’environnement et des structures de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5a8511-238c-432e-9ed6-57d97c522cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'états: 500\n",
      "Nombre d'actions: 6\n",
      "\n",
      "Premières lignes de la table de politique:\n",
      "[[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
      "\n",
      "Premières valeurs de la table de valeur:\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "# Initialisation de l’environnement\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "\n",
    "# Nombre d’états et d’actions\n",
    "state_size = env.observation_space.n\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(f\"Nombre d'états: {state_size}\")\n",
    "print(f\"Nombre d'actions: {action_size}\")\n",
    "\n",
    "# Création de la table de politique avec probabilité uniforme pour chaque action\n",
    "policy_table = np.ones((state_size, action_size)) / action_size\n",
    "\n",
    "# Création de la table de valeurs initialisée à zéro\n",
    "value_table = np.zeros(state_size)\n",
    "\n",
    "# Affichage des premières lignes des tables\n",
    "print(\"\\nPremières lignes de la table de politique:\")\n",
    "print(policy_table[:5])\n",
    "\n",
    "print(\"\\nPremières valeurs de la table de valeur:\")\n",
    "print(value_table[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03babb7f-5e02-48a1-a13d-8693f055d46c",
   "metadata": {},
   "source": [
    "# Exercice 2: Exploration et collecte d'épisodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eeb0684-d4bf-4767-bc36-0697bb05a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Épisode 1 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 5, Récompense: -10\n",
      "Étape 4 - Action: 1, Récompense: -1\n",
      "Étape 5 - Action: 5, Récompense: -10\n",
      "Étape 6 - Action: 3, Récompense: -1\n",
      "Étape 7 - Action: 4, Récompense: -10\n",
      "Étape 8 - Action: 4, Récompense: -10\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 2, Récompense: -1\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 3, Récompense: -1\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 2, Récompense: -1\n",
      "Étape 17 - Action: 1, Récompense: -1\n",
      "Étape 18 - Action: 5, Récompense: -10\n",
      "Étape 19 - Action: 0, Récompense: -1\n",
      "Étape 20 - Action: 4, Récompense: -10\n",
      "Récompense totale de l'épisode: -110\n",
      "\n",
      "Épisode 2 :\n",
      "Étape 1 - Action: 5, Récompense: -10\n",
      "Étape 2 - Action: 4, Récompense: -10\n",
      "Étape 3 - Action: 3, Récompense: -1\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 2, Récompense: -1\n",
      "Étape 6 - Action: 3, Récompense: -1\n",
      "Étape 7 - Action: 3, Récompense: -1\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 5, Récompense: -10\n",
      "Étape 10 - Action: 3, Récompense: -1\n",
      "Étape 11 - Action: 0, Récompense: -1\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 2, Récompense: -1\n",
      "Étape 14 - Action: 0, Récompense: -1\n",
      "Étape 15 - Action: 2, Récompense: -1\n",
      "Étape 16 - Action: 0, Récompense: -1\n",
      "Étape 17 - Action: 2, Récompense: -1\n",
      "Étape 18 - Action: 5, Récompense: -10\n",
      "Étape 19 - Action: 2, Récompense: -1\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -74\n",
      "\n",
      "Épisode 3 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 2, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 1, Récompense: -1\n",
      "Étape 5 - Action: 2, Récompense: -1\n",
      "Étape 6 - Action: 2, Récompense: -1\n",
      "Étape 7 - Action: 5, Récompense: -10\n",
      "Étape 8 - Action: 3, Récompense: -1\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 4, Récompense: -10\n",
      "Étape 11 - Action: 2, Récompense: -1\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 5, Récompense: -10\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 0, Récompense: -1\n",
      "Étape 17 - Action: 2, Récompense: -1\n",
      "Étape 18 - Action: 1, Récompense: -1\n",
      "Étape 19 - Action: 0, Récompense: -1\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -83\n",
      "\n",
      "Épisode 4 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 4, Récompense: -10\n",
      "Étape 3 - Action: 1, Récompense: -1\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 4, Récompense: -10\n",
      "Étape 6 - Action: 5, Récompense: -10\n",
      "Étape 7 - Action: 5, Récompense: -10\n",
      "Étape 8 - Action: 4, Récompense: -10\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 4, Récompense: -10\n",
      "Étape 12 - Action: 3, Récompense: -1\n",
      "Étape 13 - Action: 4, Récompense: -10\n",
      "Étape 14 - Action: 3, Récompense: -1\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 3, Récompense: -1\n",
      "Étape 17 - Action: 5, Récompense: -10\n",
      "Étape 18 - Action: 1, Récompense: -1\n",
      "Étape 19 - Action: 1, Récompense: -1\n",
      "Étape 20 - Action: 2, Récompense: -1\n",
      "Récompense totale de l'épisode: -110\n",
      "\n",
      "Épisode 5 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 5, Récompense: -10\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 0, Récompense: -1\n",
      "Étape 6 - Action: 2, Récompense: -1\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 0, Récompense: -1\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 0, Récompense: -1\n",
      "Étape 12 - Action: 3, Récompense: -1\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 5, Récompense: -10\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 0, Récompense: -1\n",
      "Étape 18 - Action: 4, Récompense: -10\n",
      "Étape 19 - Action: 2, Récompense: -1\n",
      "Étape 20 - Action: 4, Récompense: -10\n",
      "Récompense totale de l'épisode: -92\n",
      "\n",
      "Épisode 6 :\n",
      "Étape 1 - Action: 2, Récompense: -1\n",
      "Étape 2 - Action: 2, Récompense: -1\n",
      "Étape 3 - Action: 3, Récompense: -1\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 2, Récompense: -1\n",
      "Étape 6 - Action: 3, Récompense: -1\n",
      "Étape 7 - Action: 4, Récompense: -10\n",
      "Étape 8 - Action: 4, Récompense: -10\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 3, Récompense: -1\n",
      "Étape 11 - Action: 4, Récompense: -10\n",
      "Étape 12 - Action: 0, Récompense: -1\n",
      "Étape 13 - Action: 3, Récompense: -1\n",
      "Étape 14 - Action: 1, Récompense: -1\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 2, Récompense: -1\n",
      "Étape 18 - Action: 2, Récompense: -1\n",
      "Étape 19 - Action: 2, Récompense: -1\n",
      "Étape 20 - Action: 5, Récompense: -10\n",
      "Récompense totale de l'épisode: -65\n",
      "\n",
      "Épisode 7 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 5, Récompense: -10\n",
      "Étape 4 - Action: 5, Récompense: -10\n",
      "Étape 5 - Action: 2, Récompense: -1\n",
      "Étape 6 - Action: 1, Récompense: -1\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 2, Récompense: -1\n",
      "Étape 11 - Action: 5, Récompense: -10\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 1, Récompense: -1\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 3, Récompense: -1\n",
      "Étape 18 - Action: 2, Récompense: -1\n",
      "Étape 19 - Action: 5, Récompense: -10\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -92\n",
      "\n",
      "Épisode 8 :\n",
      "Étape 1 - Action: 2, Récompense: -1\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 5, Récompense: -10\n",
      "Étape 6 - Action: 2, Récompense: -1\n",
      "Étape 7 - Action: 4, Récompense: -10\n",
      "Étape 8 - Action: 4, Récompense: -10\n",
      "Étape 9 - Action: 1, Récompense: -1\n",
      "Étape 10 - Action: 4, Récompense: -10\n",
      "Étape 11 - Action: 3, Récompense: -1\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 0, Récompense: -1\n",
      "Étape 14 - Action: 1, Récompense: -1\n",
      "Étape 15 - Action: 0, Récompense: -1\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 1, Récompense: -1\n",
      "Étape 18 - Action: 2, Récompense: -1\n",
      "Étape 19 - Action: 2, Récompense: -1\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -74\n",
      "\n",
      "Épisode 9 :\n",
      "Étape 1 - Action: 4, Récompense: -1\n",
      "Étape 2 - Action: 0, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 0, Récompense: -1\n",
      "Étape 5 - Action: 0, Récompense: -1\n",
      "Étape 6 - Action: 2, Récompense: -1\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 1, Récompense: -1\n",
      "Étape 11 - Action: 4, Récompense: -10\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 2, Récompense: -1\n",
      "Étape 14 - Action: 3, Récompense: -1\n",
      "Étape 15 - Action: 1, Récompense: -1\n",
      "Étape 16 - Action: 4, Récompense: -10\n",
      "Étape 17 - Action: 0, Récompense: -1\n",
      "Étape 18 - Action: 5, Récompense: -10\n",
      "Étape 19 - Action: 4, Récompense: -10\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -65\n",
      "\n",
      "Épisode 10 :\n",
      "Étape 1 - Action: 4, Récompense: -10\n",
      "Étape 2 - Action: 1, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 1, Récompense: -1\n",
      "Étape 6 - Action: 4, Récompense: -10\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 2, Récompense: -1\n",
      "Étape 11 - Action: 1, Récompense: -1\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 2, Récompense: -1\n",
      "Étape 14 - Action: 1, Récompense: -1\n",
      "Étape 15 - Action: 4, Récompense: -10\n",
      "Étape 16 - Action: 2, Récompense: -1\n",
      "Étape 17 - Action: 0, Récompense: -1\n",
      "Étape 18 - Action: 3, Récompense: -1\n",
      "Étape 19 - Action: 4, Récompense: -10\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -74\n",
      "\n",
      "Épisode 11 :\n",
      "Étape 1 - Action: 2, Récompense: -1\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 5, Récompense: -10\n",
      "Étape 5 - Action: 1, Récompense: -1\n",
      "Étape 6 - Action: 5, Récompense: -10\n",
      "Étape 7 - Action: 5, Récompense: -10\n",
      "Étape 8 - Action: 3, Récompense: -1\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 1, Récompense: -1\n",
      "Étape 11 - Action: 3, Récompense: -1\n",
      "Étape 12 - Action: 3, Récompense: -1\n",
      "Étape 13 - Action: 4, Récompense: -10\n",
      "Étape 14 - Action: 2, Récompense: -1\n",
      "Étape 15 - Action: 1, Récompense: -1\n",
      "Étape 16 - Action: 4, Récompense: -10\n",
      "Étape 17 - Action: 4, Récompense: -10\n",
      "Étape 18 - Action: 1, Récompense: -1\n",
      "Étape 19 - Action: 4, Récompense: -10\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -92\n",
      "\n",
      "Épisode 12 :\n",
      "Étape 1 - Action: 0, Récompense: -1\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 5, Récompense: -10\n",
      "Étape 4 - Action: 1, Récompense: -1\n",
      "Étape 5 - Action: 1, Récompense: -1\n",
      "Étape 6 - Action: 5, Récompense: -10\n",
      "Étape 7 - Action: 1, Récompense: -1\n",
      "Étape 8 - Action: 5, Récompense: -10\n",
      "Étape 9 - Action: 5, Récompense: -10\n",
      "Étape 10 - Action: 2, Récompense: -1\n",
      "Étape 11 - Action: 0, Récompense: -1\n",
      "Étape 12 - Action: 2, Récompense: -1\n",
      "Étape 13 - Action: 4, Récompense: -10\n",
      "Étape 14 - Action: 1, Récompense: -1\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 4, Récompense: -10\n",
      "Étape 17 - Action: 0, Récompense: -1\n",
      "Étape 18 - Action: 0, Récompense: -1\n",
      "Étape 19 - Action: 1, Récompense: -1\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -74\n",
      "\n",
      "Épisode 13 :\n",
      "Étape 1 - Action: 1, Récompense: -1\n",
      "Étape 2 - Action: 1, Récompense: -1\n",
      "Étape 3 - Action: 3, Récompense: -1\n",
      "Étape 4 - Action: 5, Récompense: -10\n",
      "Étape 5 - Action: 5, Récompense: -10\n",
      "Étape 6 - Action: 4, Récompense: -10\n",
      "Étape 7 - Action: 1, Récompense: -1\n",
      "Étape 8 - Action: 1, Récompense: -1\n",
      "Étape 9 - Action: 5, Récompense: -10\n",
      "Étape 10 - Action: 2, Récompense: -1\n",
      "Étape 11 - Action: 3, Récompense: -1\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 0, Récompense: -1\n",
      "Étape 14 - Action: 2, Récompense: -1\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 0, Récompense: -1\n",
      "Étape 17 - Action: 3, Récompense: -1\n",
      "Étape 18 - Action: 0, Récompense: -1\n",
      "Étape 19 - Action: 3, Récompense: -1\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -65\n",
      "\n",
      "Épisode 14 :\n",
      "Étape 1 - Action: 5, Récompense: -10\n",
      "Étape 2 - Action: 0, Récompense: -1\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 1, Récompense: -1\n",
      "Étape 6 - Action: 5, Récompense: -10\n",
      "Étape 7 - Action: 0, Récompense: -1\n",
      "Étape 8 - Action: 1, Récompense: -1\n",
      "Étape 9 - Action: 4, Récompense: -10\n",
      "Étape 10 - Action: 1, Récompense: -1\n",
      "Étape 11 - Action: 4, Récompense: -10\n",
      "Étape 12 - Action: 4, Récompense: -10\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 5, Récompense: -10\n",
      "Étape 15 - Action: 3, Récompense: -1\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 4, Récompense: -10\n",
      "Étape 18 - Action: 4, Récompense: -10\n",
      "Étape 19 - Action: 5, Récompense: -10\n",
      "Étape 20 - Action: 5, Récompense: -10\n",
      "Récompense totale de l'épisode: -137\n",
      "\n",
      "Épisode 15 :\n",
      "Étape 1 - Action: 3, Récompense: -1\n",
      "Étape 2 - Action: 5, Récompense: -10\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 3, Récompense: -1\n",
      "Étape 5 - Action: 4, Récompense: -10\n",
      "Étape 6 - Action: 5, Récompense: -10\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 3, Récompense: -1\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 4, Récompense: -10\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 0, Récompense: -1\n",
      "Étape 17 - Action: 5, Récompense: -10\n",
      "Étape 18 - Action: 0, Récompense: -1\n",
      "Étape 19 - Action: 5, Récompense: -10\n",
      "Étape 20 - Action: 2, Récompense: -1\n",
      "Récompense totale de l'épisode: -110\n",
      "\n",
      "Épisode 16 :\n",
      "Étape 1 - Action: 3, Récompense: -1\n",
      "Étape 2 - Action: 0, Récompense: -1\n",
      "Étape 3 - Action: 0, Récompense: -1\n",
      "Étape 4 - Action: 2, Récompense: -1\n",
      "Étape 5 - Action: 2, Récompense: -1\n",
      "Étape 6 - Action: 3, Récompense: -1\n",
      "Étape 7 - Action: 1, Récompense: -1\n",
      "Étape 8 - Action: 3, Récompense: -1\n",
      "Étape 9 - Action: 1, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 5, Récompense: -10\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 1, Récompense: -1\n",
      "Étape 14 - Action: 4, Récompense: -10\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 5, Récompense: -10\n",
      "Étape 17 - Action: 1, Récompense: -1\n",
      "Étape 18 - Action: 0, Récompense: -1\n",
      "Étape 19 - Action: 3, Récompense: -1\n",
      "Étape 20 - Action: 1, Récompense: -1\n",
      "Récompense totale de l'épisode: -65\n",
      "\n",
      "Épisode 17 :\n",
      "Étape 1 - Action: 5, Récompense: -10\n",
      "Étape 2 - Action: 4, Récompense: -10\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 0, Récompense: -1\n",
      "Étape 5 - Action: 5, Récompense: -10\n",
      "Étape 6 - Action: 1, Récompense: -1\n",
      "Étape 7 - Action: 2, Récompense: -1\n",
      "Étape 8 - Action: 3, Récompense: -1\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 0, Récompense: -1\n",
      "Étape 11 - Action: 4, Récompense: -10\n",
      "Étape 12 - Action: 5, Récompense: -10\n",
      "Étape 13 - Action: 3, Récompense: -1\n",
      "Étape 14 - Action: 2, Récompense: -1\n",
      "Étape 15 - Action: 0, Récompense: -1\n",
      "Étape 16 - Action: 2, Récompense: -1\n",
      "Étape 17 - Action: 4, Récompense: -10\n",
      "Étape 18 - Action: 0, Récompense: -1\n",
      "Étape 19 - Action: 2, Récompense: -1\n",
      "Étape 20 - Action: 5, Récompense: -10\n",
      "Récompense totale de l'épisode: -92\n",
      "\n",
      "Épisode 18 :\n",
      "Étape 1 - Action: 1, Récompense: -1\n",
      "Étape 2 - Action: 3, Récompense: -1\n",
      "Étape 3 - Action: 4, Récompense: -10\n",
      "Étape 4 - Action: 4, Récompense: -10\n",
      "Étape 5 - Action: 5, Récompense: -10\n",
      "Étape 6 - Action: 0, Récompense: -1\n",
      "Étape 7 - Action: 1, Récompense: -1\n",
      "Étape 8 - Action: 4, Récompense: -10\n",
      "Étape 9 - Action: 3, Récompense: -1\n",
      "Étape 10 - Action: 4, Récompense: -10\n",
      "Étape 11 - Action: 1, Récompense: -1\n",
      "Étape 12 - Action: 0, Récompense: -1\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 4, Récompense: -10\n",
      "Étape 15 - Action: 4, Récompense: -10\n",
      "Étape 16 - Action: 4, Récompense: -10\n",
      "Étape 17 - Action: 1, Récompense: -1\n",
      "Étape 18 - Action: 4, Récompense: -10\n",
      "Étape 19 - Action: 5, Récompense: -10\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -119\n",
      "\n",
      "Épisode 19 :\n",
      "Étape 1 - Action: 5, Récompense: -10\n",
      "Étape 2 - Action: 2, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 2, Récompense: -1\n",
      "Étape 5 - Action: 3, Récompense: -1\n",
      "Étape 6 - Action: 0, Récompense: -1\n",
      "Étape 7 - Action: 5, Récompense: -10\n",
      "Étape 8 - Action: 2, Récompense: -1\n",
      "Étape 9 - Action: 0, Récompense: -1\n",
      "Étape 10 - Action: 1, Récompense: -1\n",
      "Étape 11 - Action: 0, Récompense: -1\n",
      "Étape 12 - Action: 1, Récompense: -1\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 0, Récompense: -1\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 1, Récompense: -1\n",
      "Étape 17 - Action: 4, Récompense: -10\n",
      "Étape 18 - Action: 4, Récompense: -10\n",
      "Étape 19 - Action: 5, Récompense: -10\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -83\n",
      "\n",
      "Épisode 20 :\n",
      "Étape 1 - Action: 2, Récompense: -1\n",
      "Étape 2 - Action: 2, Récompense: -1\n",
      "Étape 3 - Action: 2, Récompense: -1\n",
      "Étape 4 - Action: 2, Récompense: -1\n",
      "Étape 5 - Action: 3, Récompense: -1\n",
      "Étape 6 - Action: 1, Récompense: -1\n",
      "Étape 7 - Action: 4, Récompense: -10\n",
      "Étape 8 - Action: 1, Récompense: -1\n",
      "Étape 9 - Action: 5, Récompense: -10\n",
      "Étape 10 - Action: 4, Récompense: -10\n",
      "Étape 11 - Action: 0, Récompense: -1\n",
      "Étape 12 - Action: 0, Récompense: -1\n",
      "Étape 13 - Action: 5, Récompense: -10\n",
      "Étape 14 - Action: 5, Récompense: -10\n",
      "Étape 15 - Action: 5, Récompense: -10\n",
      "Étape 16 - Action: 0, Récompense: -1\n",
      "Étape 17 - Action: 1, Récompense: -1\n",
      "Étape 18 - Action: 4, Récompense: -10\n",
      "Étape 19 - Action: 3, Récompense: -1\n",
      "Étape 20 - Action: 0, Récompense: -1\n",
      "Récompense totale de l'épisode: -83\n"
     ]
    }
   ],
   "source": [
    "# Nombre d'épisodes\n",
    "num_episodes = 20\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()  # Initialisation de l'état\n",
    "    total_reward = 0\n",
    "\n",
    "    print(f\"\\nÉpisode {episode + 1} :\")\n",
    "\n",
    "    for t in range(20):  # Exécuter 20 étapes par épisode\n",
    "        action = env.action_space.sample()  # Choix d'une action aléatoire\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "        print(f\"Étape {t + 1} - Action: {action}, Récompense: {reward}\")\n",
    "\n",
    "        if done:  # Si l'épisode se termine avant 20 étapes\n",
    "            break\n",
    "\n",
    "    print(f\"Récompense totale de l'épisode: {total_reward}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e6bd7-907f-4dc0-890c-793fc4d997b1",
   "metadata": {},
   "source": [
    "# Exercice 3: Mise a jour de la politique avec PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5c9dc9-6c75-4ed2-b1a2-3e8e2b193003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table de politique mise à jour (extrait) : [[0.16666667 0.2        0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.2        0.16666667 0.16666667 0.16666667]\n",
      " [0.2        0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.2        0.16666667 0.16666667]\n",
      " [0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]]\n",
      "Table de valeurs mise à jour (extrait) : [1.47725916 0.48207998 0.99200001 0.8        0.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hyperparamètres\n",
    "gamma = 0.99  # Facteur d'actualisation des récompenses futures\n",
    "lr_policy = 0.1  # Taux d'apprentissage pour la politique\n",
    "lr_value = 0.1  # Taux d'apprentissage pour la fonction de valeur\n",
    "clip_epsilon = 0.2  # Seuil de clipping\n",
    "\n",
    "\n",
    "\n",
    "def compute_discounted_rewards(rewards, gamma):\n",
    "    \"\"\"Calcule les récompenses cumulées (discounted rewards).\"\"\"\n",
    "    discounted_rewards = np.zeros_like(rewards, dtype=np.float32)\n",
    "    cumulative_reward = 0\n",
    "    for t in reversed(range(len(rewards))):\n",
    "        cumulative_reward = rewards[t] + gamma * cumulative_reward\n",
    "        discounted_rewards[t] = cumulative_reward\n",
    "    return discounted_rewards\n",
    "\n",
    "def update_policy_value(policy_table, value_table, states, actions, rewards):\n",
    "    \"\"\"Met à jour la politique et la fonction de valeur avec PPO.\"\"\"\n",
    "    # Calcul des récompenses cumulées\n",
    "    discounted_rewards = compute_discounted_rewards(rewards, gamma)\n",
    "\n",
    "    for t in range(len(states)):\n",
    "        state, action, reward = states[t], actions[t], rewards[t]\n",
    "        \n",
    "        # Calcul de l'avantage At = Rt - V(st)\n",
    "        advantage = discounted_rewards[t] - value_table[state]\n",
    "\n",
    "        # Mise à jour de la fonction de valeur avec une learning rate\n",
    "        value_table[state] += lr_value * advantage\n",
    "\n",
    "        # Mise à jour de la politique avec clipping\n",
    "        old_prob = policy_table[state, action]\n",
    "        new_prob = old_prob * np.exp(lr_policy * advantage)  # Mise à jour proportionnelle\n",
    "        new_prob = np.clip(new_prob, old_prob * (1 - clip_epsilon), old_prob * (1 + clip_epsilon))  # Clipping\n",
    "        \n",
    "        # Normalisation de la distribution des probabilités\n",
    "        policy_table[state] = policy_table[state] / np.sum(policy_table[state])  # Normalisation\n",
    "        policy_table[state, action] = new_prob  # Mise à jour de la probabilité de l'action sélectionnée\n",
    "\n",
    "    return policy_table, value_table\n",
    "\n",
    "# Exemple d'utilisation\n",
    "episode_states = [0, 1, 2, 3]  # Liste des états visités (exemple)\n",
    "episode_actions = [1, 2, 0, 3]  # Liste des actions prises\n",
    "episode_rewards = [10, -5, 2, 8]  # Liste des récompenses obtenues\n",
    "\n",
    "# Mise à jour de la politique et des valeurs\n",
    "policy_table, value_table = update_policy_value(policy_table, value_table, episode_states, episode_actions, episode_rewards)\n",
    "\n",
    "print(\"Table de politique mise à jour (extrait) :\", policy_table[:5])\n",
    "print(\"Table de valeurs mise à jour (extrait) :\", value_table[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e369b-df59-4e91-b6f8-42c5b4555a77",
   "metadata": {},
   "source": [
    "# Exercice 4 : Évaluation de l’agent après entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f41168-1304-47b8-bf8d-f75c4ad23b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 1, Récompense totale: -100\n",
      "Épisode 2, Récompense totale: -100\n",
      "Épisode 3, Récompense totale: -100\n",
      "Épisode 4, Récompense totale: -100\n",
      "Épisode 5, Récompense totale: -100\n",
      "Épisode 6, Récompense totale: -100\n",
      "Épisode 7, Récompense totale: -100\n",
      "Épisode 8, Récompense totale: -100\n",
      "Épisode 9, Récompense totale: -100\n",
      "Épisode 10, Récompense totale: -100\n",
      "Épisode 11, Récompense totale: -100\n",
      "Épisode 12, Récompense totale: -100\n",
      "Épisode 13, Récompense totale: -100\n",
      "Épisode 14, Récompense totale: -100\n",
      "Épisode 15, Récompense totale: -100\n",
      "Épisode 16, Récompense totale: -100\n",
      "Épisode 17, Récompense totale: -100\n",
      "Épisode 18, Récompense totale: -100\n",
      "Épisode 19, Récompense totale: -100\n",
      "Épisode 20, Récompense totale: -100\n",
      "Récompense moyenne après entraînement: -100.0\n"
     ]
    }
   ],
   "source": [
    "num_eval_episodes = 20\n",
    "total_rewards = []\n",
    "max_steps = 100  # Prevents infinite loops\n",
    "\n",
    "for ep in range(num_eval_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    steps = 0  # Step counter\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        # Normalize policy before selecting action (prevents NaNs)\n",
    "        action_probs = policy_table[state] / np.sum(policy_table[state] + 1e-8)  \n",
    "        action = np.argmax(action_probs)  \n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        steps += 1  # Increase step count\n",
    "\n",
    "    total_rewards.append(total_reward)\n",
    "    print(f\"Épisode {ep + 1}, Récompense totale: {total_reward}\")\n",
    "\n",
    "# Avoid infinite mean if total_rewards is empty\n",
    "mean_reward = np.mean(total_rewards) if total_rewards else 0\n",
    "print(\"Récompense moyenne après entraînement:\", mean_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
